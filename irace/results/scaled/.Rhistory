train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#PoolQC is however excluded since in is uneffective (sparse actual values - the information gain could be random)
#Fence excluded ???
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#PoolQC is however excluded since in is uneffective (sparse actual values - the information gain could be random)
#Fence excluded ???
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, OpenPorchSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#PoolQC is however excluded since in is uneffective (sparse actual values - the information gain could be random)
#Fence excluded ???
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, LotArea, OpenPorchSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#PoolQC is however excluded since in is uneffective (sparse actual values - the information gain could be random)
#Fence excluded ???
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF,Fireplaces, LotArea, OpenPorchSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#PoolQC is however excluded since in is uneffective (sparse actual values - the information gain could be random)
#Fence and MiscFeature excluded ???
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#PoolQC, Fence and MiscFeature are however excluded since in is uneffective (sparse actual values - the information gain could be random)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
#text(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
text(regtree)
text(regtree, pretty = 0)
text(regtree)
text(regtree)
plot(regtree)
text(regtree)
plot(regtree)
text(regtree, pretty=0)
tree.control(nobs, mincut = 5, minsize = 10, mindev = 0.01)
tree.control(nobs=1, mincut = 5, minsize = 10, mindev = 0.01)
regtree = tree(SalePrice~., train)
plot(regtree)
text(regtree, pretty=0)
tree.control(nobs=1, mincut = 5, minsize = 2, mindev = 0)
tree.control(nobs=1, mincut = 1, minsize = 2, mindev = 0)
regtree = tree(SalePrice~., train)
plot(regtree)
text(regtree, pretty=0)
tree.control(nobs=10, mincut = 1, minsize = 20, mindev = 10)
regtree = tree(SalePrice~., train)
plot(regtree)
text(regtree, pretty=0)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
plot(tree.pruned)
install.packages("lazy")
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
View(train)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(tree)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, TotalBsmtSF, MSSubClass, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation, Fence,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, FireplaceQu, YearRemodAdd, Foundation, Fence,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
LotFrontage, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, MasVnrArea,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = lazy(SalePrice~., train)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation, Fence,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, MiscFeature, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
tree.control(nobs=10, mincut = 1, minsize = 20, mindev = 10)
regtree = tree(SalePrice~., train)
plot(regtree)
text(regtree, pretty=0)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(tree)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, Neighborhood, Alley, GrLivArea,
GarageCars, GarageArea, YearBuilt, ExterQual, KitchenQual, TotalBsmtSF, BsmtQual, MSSubClass,
X1stFlrSF, FullBath, GarageYrBlt, GarageFinish, FireplaceQu, YearRemodAdd, Foundation,
LotFrontage, GarageType, TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
Exterior1st, Exterior2nd, HeatingQC, BsmtFinType1, BsmtFinSF1, MSZoning, MasVnrArea, MasVnrType,
HouseStyle, OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
regtree = tree(SalePrice~., train)
plot(regtree)
row = train[,1:(ncol(train)-1)]
row[,"PredictedPrice"] = predict(regtree, row)
row[,"RealPrice"] = train[,"SalePrice"]
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, LotFrontage
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, LotFrontage,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
View(train)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1, GarageYrBlt,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
result[,"GarageYrBlt"] = rapply(result[,"GarageYrBlt"], f=function(x) ifelse(is.nan(x),0,x), how="replace")
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
library(lazy)
#Filters the train dataframe
#Only higher than 0.1 IG features were selected
#Non-numeric and sparse features are however excluded since in is uneffective
#LotFrontage and GarageYrBlt and MasVnrArea excluded because of NaN values
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
con=lazy.control(conIdPar=NULL, linIdPar=1, quaIdPar=NULL,
distance=c("manhattan","euclidean"), metric=NULL,
cmbPar=1, lambda=1e+03)
model = lazy(SalePrice~., train,control=con)
prediction = train[,1:(ncol(train)-1)]
prediction[,"PredictedPrice"] = predict(model, prediction)
prediction[,"RealPrice"] = train[,"SalePrice"]
rmse = sqrt(mean(prediction[,"PredictedPrice"] - prediction[,"RealPrice"])^2)
print(rmse)
View(prediction)
framesize = 300
while (nrow(train) > 0)
{
train = train[(framesize+1):nrow(train),]
}
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
framesize = 300
x=1
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize)]
x = x + framesize
}
framesize = 300
x=1
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize)];
x = x + framesize;
}
framesize = 300
x=1
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize),];
x = x + framesize;
}
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
framesize = 300
x=1
newf=0
while (nrow(train) > 0)
{
newf <- train[x:(x+framesize),];
x = x + framesize;
}
framesize = 300
x=1
newf=0
while (x < nrow(train))
{
newf <- train[x:(x+framesize),];
x = x + framesize;
}
a = list("a", "b")
a = a + "c"
a = list(a, "c")
a = list("a", "b")
a = c(a, "c")
a = list("a", "b")
a = c(a, "c")
newf=list()
framesize = 300
x=1
newf=0
part
framesize = 300
x=1
newf=0
part=list()
while (x < nrow(train))
{
newf <- train[x:(x+framesize-1),];
part = c(part, newf)
x = x + framesize;
}
print(part)
framesize = 300
x=1
newf=0
part=list()
newf <- train[x:(x+framesize-1),];
View(newf)
data=[,,]
data=data.frame(2,3,4)
View(data)
library(lazy)
feature_filter <- function(input) {
result <- subset(input, select=c(OverallQual, GrLivArea,
GarageCars, GarageArea, YearBuilt, TotalBsmtSF, MSSubClass,
X1stFlrSF, FullBath, YearRemodAdd,
TotRmsAbvGrd, X2ndFlrSF, Fireplaces, LotArea, OpenPorchSF,
BsmtFinSF1,
OverallCond, WoodDeckSF, HalfBath, BsmtUnfSF, SalePrice))
return(result)
}
train_raw = read.csv("D:\\kaggle\\train.csv", header = TRUE)
train = feature_filter(train_raw)
framesize = 300
x=1
newf=0
part=list()
newf <- train[x:(x+framesize-1),];
View(newf)
part = c(part, newf)
x = x + framesize;
part[1]
boxplot(mpg~cyl,data=mtcars, main="Car Milage Data",
xlab="Number of Cylinders", ylab="Miles Per Gallon")
MyData <- read.csv(file="raw3.txt", header=TRUE, sep=",")
setwd("D:\\master\\irace\\results\\scaled")
MyData <- read.csv(file="raw3.txt", header=TRUE, sep=",")
View(MyData)
boxplot(mpg~cyl,data=MyData, main="Car Milage Data",
xlab="Number of Cylinders", ylab="Miles Per Gallon")
boxplot(data=MyData, main="Car Milage Data",
xlab="Number of Cylinders", ylab="Miles Per Gallon")
boxplot(Best ~ Obtained, data=MyData, main="Car Milage Data",
xlab="Number of Cylinders", ylab="Miles Per Gallon")
